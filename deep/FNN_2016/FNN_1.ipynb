{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score, log_loss, accuracy_score\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv('data/train.csv')\n",
    "test_X = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>7</td>\n",
       "      <td>0.044131</td>\n",
       "      <td>9</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>6</td>\n",
       "      <td>0.048052</td>\n",
       "      <td>9</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>4</td>\n",
       "      <td>0.137581</td>\n",
       "      <td>11</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>4</td>\n",
       "      <td>0.150486</td>\n",
       "      <td>1</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>4</td>\n",
       "      <td>0.220635</td>\n",
       "      <td>9</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  education_num  marital_status  \\\n",
       "0  0.301370          7  0.044131          9       0.800000               4   \n",
       "1  0.452055          6  0.048052          9       0.800000               2   \n",
       "2  0.287671          4  0.137581         11       0.533333               0   \n",
       "3  0.493151          4  0.150486          1       0.400000               2   \n",
       "4  0.150685          4  0.220635          9       0.800000               2   \n",
       "\n",
       "   occupation  relationship  race  sex  capital_gain  capital_loss  \\\n",
       "0           1             1     4    1       0.02174           0.0   \n",
       "1           4             0     4    1       0.00000           0.0   \n",
       "2           6             1     4    1       0.00000           0.0   \n",
       "3           6             0     2    1       0.00000           0.0   \n",
       "4          10             5     2    0       0.00000           0.0   \n",
       "\n",
       "   hours_per_week  native_country  \n",
       "0        0.397959              39  \n",
       "1        0.122449              39  \n",
       "2        0.397959              39  \n",
       "3        0.397959              39  \n",
       "4        0.397959               5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 14 columns):\n",
      "age               32561 non-null float64\n",
      "workclass         32561 non-null int64\n",
      "fnlwgt            32561 non-null float64\n",
      "education         32561 non-null int64\n",
      "education_num     32561 non-null float64\n",
      "marital_status    32561 non-null int64\n",
      "occupation        32561 non-null int64\n",
      "relationship      32561 non-null int64\n",
      "race              32561 non-null int64\n",
      "sex               32561 non-null int64\n",
      "capital_gain      32561 non-null float64\n",
      "capital_loss      32561 non-null float64\n",
      "hours_per_week    32561 non-null float64\n",
      "native_country    32561 non-null int64\n",
      "dtypes: float64(6), int64(8)\n",
      "memory usage: 3.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = pd.read_csv('data/y_train.csv')\n",
    "test_Y = pd.read_csv('data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   income_label\n",
       "0             0\n",
       "1             0\n",
       "2             0\n",
       "3             0\n",
       "4             0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 1 columns):\n",
      "income_label    32561 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 254.5 KB\n"
     ]
    }
   ],
   "source": [
    "train_Y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_feature = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "category_feature = ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataParse:\n",
    "    def __init__(self, category_feature, continuous_feature, ignore_feature=[], feature_dict={}, feature_size=0, field_size=0):\n",
    "        self.feature_dict = feature_dict\n",
    "        self.feature_size = feature_size\n",
    "        self.field_size = field_size\n",
    "        self.ignore_feature = ignore_feature\n",
    "        self.category_feature = category_feature\n",
    "        self.continuous_feature = continuous_feature\n",
    "    \n",
    "    def FeatureDictionary(self, train, test):\n",
    "        \"\"\"\n",
    "        目的是给每一个特征维度都进行编号。\n",
    "        1. 对于离散特征，one-hot之后每一列都是一个新的特征维度(计算编号时，不算0)。所以，原来的一维度对应的是很多维度，编号也是不同的。\n",
    "        2. 对于连续特征，原来的一维特征依旧是一维特征。\n",
    "        返回一个feat_dict，用于根据原特征名称和特征取值 快速查询出 对应的特征编号。\n",
    "        train: 原始训练集\n",
    "        test:  原始测试集\n",
    "        continuous_feature: 所有数值型特征\n",
    "        ignore_feature: 所有忽略的特征. 除了数值型和忽略的，剩下的全部认为是离散型\n",
    "        feat_dict, feat_size\n",
    "             1. feat_size: one-hot之后总的特征维度。\n",
    "             2. feat_dict是一个{}， key是特征string的col_name, value可能是编号（int），可能也是一个字典。\n",
    "             如果原特征是连续特征： value就是int，表示对应的特征编号；\n",
    "             如果原特征是离散特征：value就是dict，里面是根据离散特征的 实际取值 查询 该维度的特征编号。 因为离散特征one-hot之后，\n",
    "             一个取值就是一个维度，而一个维度就对应一个编号。\n",
    "        \"\"\"\n",
    "        df = pd.concat([train, test], axis=0)\n",
    "        feat_dict = {}\n",
    "        total_cnt = 0\n",
    "        \n",
    "        for col in df.columns:\n",
    "            # 连续特征只有一个编号\n",
    "            if col in self.continuous_feature:\n",
    "                feat_dict[col] = total_cnt\n",
    "                total_cnt = total_cnt + 1\n",
    "            elif col in self.category_feature:\n",
    "                unique_vals = df[col].unique()\n",
    "                unique_cnt = df[col].nunique()\n",
    "                feat_dict[col] = dict(zip(unique_vals, range(total_cnt, total_cnt + unique_cnt)))\n",
    "                total_cnt = total_cnt + unique_cnt\n",
    "        \n",
    "        self.feature_size = total_cnt\n",
    "        self.feature_dict = feat_dict\n",
    "        print('feat_dict=', feat_dict)\n",
    "        print('feature_size=', total_cnt)\n",
    "    \n",
    "    def parse(self, df):\n",
    "        dfi = df.copy()\n",
    "        dfv = df.copy()\n",
    "        for col in dfi.columns:\n",
    "            if col in self.ignore_feature:\n",
    "                dfi.drop([col], axis=1, inplace=True)\n",
    "                dfv.drop([col], axis=1, inplace=True)\n",
    "\n",
    "            elif col in self.continuous_feature:  # 连续特征1个维度，对应1个编号，这个编号是一个定值\n",
    "                dfi[col] = self.feature_dict[col]\n",
    "\n",
    "            elif col in self.category_feature:  # 离散特征。不同取值对应不同的特征维度，编号也是不同的。\n",
    "                dfi[col] = dfi[col].map(self.feature_dict[col])\n",
    "                dfv[col] = 1.0\n",
    "\n",
    "        feature_index = dfi.values.tolist()\n",
    "        feature_val = dfv.values.tolist()\n",
    "        self.field_size = len(feature_index[0])\n",
    "        del dfi, dfv\n",
    "        gc.collect()\n",
    "\n",
    "        return feature_index, feature_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_dict= {'age': 0, 'workclass': {7: 1, 6: 2, 4: 3, 1: 4, 2: 5, 0: 6, 5: 7, 8: 8, 3: 9}, 'fnlwgt': 10, 'education': {9: 11, 11: 12, 1: 13, 12: 14, 6: 15, 15: 16, 7: 17, 8: 18, 5: 19, 10: 20, 14: 21, 4: 22, 0: 23, 3: 24, 13: 25, 2: 26}, 'education_num': 27, 'marital_status': {4: 28, 2: 29, 0: 30, 3: 31, 5: 32, 1: 33, 6: 34}, 'occupation': {1: 35, 4: 36, 6: 37, 10: 38, 8: 39, 12: 40, 3: 41, 14: 42, 5: 43, 7: 44, 13: 45, 0: 46, 11: 47, 2: 48, 9: 49}, 'relationship': {1: 50, 0: 51, 5: 52, 3: 53, 4: 54, 2: 55}, 'race': {4: 56, 2: 57, 1: 58, 0: 59, 3: 60}, 'sex': {1: 61, 0: 62}, 'capital_gain': 63, 'capital_loss': 64, 'hours_per_week': 65, 'native_country': {39: 66, 5: 67, 23: 68, 19: 69, 0: 70, 26: 71, 35: 72, 33: 73, 16: 74, 9: 75, 2: 76, 11: 77, 20: 78, 30: 79, 22: 80, 31: 81, 4: 82, 1: 83, 37: 84, 7: 85, 25: 86, 36: 87, 14: 88, 32: 89, 6: 90, 8: 91, 10: 92, 13: 93, 3: 94, 24: 95, 41: 96, 29: 97, 28: 98, 34: 99, 38: 100, 12: 101, 27: 102, 40: 103, 17: 104, 21: 105, 18: 106, 15: 107}}\n",
      "feature_size= 108\n"
     ]
    }
   ],
   "source": [
    "dataParse = DataParse(continuous_feature=continuous_feature, category_feature=category_feature)\n",
    "dataParse.FeatureDictionary(train_X, test_X)\n",
    "train_feature_index, train_feature_val = dataParse.parse(train_X)\n",
    "test_feature_index, test_feature_val = dataParse.parse(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = train_Y.values.reshape(-1, 1)\n",
    "test_Y = test_Y.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_db = tf.data.Dataset.from_tensor_slices((train_feature_index, train_feature_val, train_Y))\n",
    "test_db = tf.data.Dataset.from_tensor_slices((test_feature_index, test_feature_val, test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_db = train_db.shuffle(2000).batch(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "embedding_size = 8\n",
    "learning_rate = 0.001\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 32\n",
    "drop_rate = 0.1\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_normal = tf.initializers.RandomNormal()\n",
    "weights = {\n",
    "    'embedding': tf.Variable(random_normal([dataParse.feature_size, embedding_size])),\n",
    "    'layer1': tf.Variable(random_normal([dataParse.field_size*embedding_size, n_hidden_1])),\n",
    "    'layer2': tf.Variable(random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out':  tf.Variable(random_normal([n_hidden_2, 1]))\n",
    "}\n",
    "biases = {\n",
    "    'layer1': tf.Variable(tf.zeros([n_hidden_1])),\n",
    "    'layer2': tf.Variable(tf.zeros([ n_hidden_2])),\n",
    "    'out': tf.Variable(tf.zeros([1]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnn_net(feature_index, feature_value):\n",
    "    embeddings = tf.nn.embedding_lookup(weights['embedding'], feature_index)  # [None, field_size, embedding_size]\n",
    "    feat_value = tf.reshape(feature_value, shape=[-1, dataParse.field_size, 1])  # [None, field_size, 1]\n",
    "    embeddings = tf.multiply(embeddings, feat_value)\n",
    "    embeddings = tf.reshape(embeddings, [-1, dataParse.field_size * embedding_size])\n",
    "    \n",
    "    layer_1 = tf.add(tf.matmul(embeddings, weights['layer1']), biases['layer1'])\n",
    "    layer_1 = tf.nn.dropout(layer_1, rate=drop_rate)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['layer2']), biases['layer2'])\n",
    "    layer_2 = tf.nn.dropout(layer_2, rate=drop_rate)\n",
    "    \n",
    "    out = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimization(feature_index, feature_value, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logit = fnn_net(feature_index, feature_value)\n",
    "        y = tf.cast(y, tf.float32)\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logit))\n",
    "        trainable_variables = list(weights.values()) + list(biases.values())\n",
    "        grad = tape.gradient(loss, trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grad, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 0.364972, auc: 0.897436\n",
      "step: 50, loss: 0.371608, auc: 0.850343\n",
      "step: 100, loss: 0.343314, auc: 0.902018\n",
      "step: 150, loss: 0.276011, auc: 0.935547\n",
      "step: 200, loss: 0.340474, auc: 0.849132\n",
      "step: 250, loss: 0.363641, auc: 0.896572\n",
      "step: 0, loss: 0.317753, auc: 0.915012\n",
      "step: 50, loss: 0.358479, auc: 0.896283\n",
      "step: 100, loss: 0.275526, auc: 0.923720\n",
      "step: 150, loss: 0.271648, auc: 0.938435\n",
      "step: 200, loss: 0.255456, auc: 0.907660\n",
      "step: 250, loss: 0.360771, auc: 0.886762\n",
      "step: 0, loss: 0.327674, auc: 0.915761\n",
      "step: 50, loss: 0.322903, auc: 0.909831\n",
      "step: 100, loss: 0.329224, auc: 0.900357\n",
      "step: 150, loss: 0.345543, auc: 0.885933\n",
      "step: 200, loss: 0.344086, auc: 0.889237\n",
      "step: 250, loss: 0.345721, auc: 0.885933\n",
      "step: 0, loss: 0.366712, auc: 0.885795\n",
      "step: 50, loss: 0.319644, auc: 0.887857\n",
      "step: 100, loss: 0.319292, auc: 0.917526\n",
      "step: 150, loss: 0.318819, auc: 0.910200\n",
      "step: 200, loss: 0.352013, auc: 0.898246\n",
      "step: 250, loss: 0.308153, auc: 0.912205\n",
      "step: 0, loss: 0.313411, auc: 0.910832\n",
      "step: 50, loss: 0.309800, auc: 0.904286\n",
      "step: 100, loss: 0.294886, auc: 0.925653\n",
      "step: 150, loss: 0.488696, auc: 0.853010\n",
      "step: 200, loss: 0.341136, auc: 0.909536\n",
      "step: 250, loss: 0.310217, auc: 0.920247\n",
      "step: 0, loss: 0.382289, auc: 0.882949\n",
      "step: 50, loss: 0.317653, auc: 0.905259\n",
      "step: 100, loss: 0.380301, auc: 0.872963\n",
      "step: 150, loss: 0.307613, auc: 0.920000\n",
      "step: 200, loss: 0.310166, auc: 0.892534\n",
      "step: 250, loss: 0.276354, auc: 0.916667\n",
      "step: 0, loss: 0.345602, auc: 0.913636\n",
      "step: 50, loss: 0.287056, auc: 0.929954\n",
      "step: 100, loss: 0.298668, auc: 0.909731\n",
      "step: 150, loss: 0.295509, auc: 0.930851\n",
      "step: 200, loss: 0.338631, auc: 0.887844\n",
      "step: 250, loss: 0.321232, auc: 0.890722\n",
      "step: 0, loss: 0.329526, auc: 0.908547\n",
      "step: 50, loss: 0.318976, auc: 0.920430\n",
      "step: 100, loss: 0.225180, auc: 0.960029\n",
      "step: 150, loss: 0.373835, auc: 0.873129\n",
      "step: 200, loss: 0.325197, auc: 0.889989\n",
      "step: 250, loss: 0.355347, auc: 0.894022\n",
      "step: 0, loss: 0.399854, auc: 0.878911\n",
      "step: 50, loss: 0.325194, auc: 0.906122\n",
      "step: 100, loss: 0.302753, auc: 0.899417\n",
      "step: 150, loss: 0.368485, auc: 0.847379\n",
      "step: 200, loss: 0.286690, auc: 0.926107\n",
      "step: 250, loss: 0.348408, auc: 0.886762\n",
      "step: 0, loss: 0.282050, auc: 0.927409\n",
      "step: 50, loss: 0.286689, auc: 0.904247\n",
      "step: 100, loss: 0.321961, auc: 0.883929\n",
      "step: 150, loss: 0.334334, auc: 0.905684\n",
      "step: 200, loss: 0.326335, auc: 0.906758\n",
      "step: 250, loss: 0.291329, auc: 0.936713\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for step, (feature_index, feature_value, y) in enumerate(train_db):\n",
    "        run_optimization(feature_index, feature_value, y)\n",
    "        \n",
    "        if step % display_step == 0:\n",
    "            pred = fnn_net(feature_index, feature_value)\n",
    "            y = tf.cast(y, tf.float32)\n",
    "            loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=pred))\n",
    "            auc = tf.reduce_mean(roc_auc_score(y, tf.nn.sigmoid(pred)))\n",
    "            print(\"step: %i, loss: %f, auc: %f\" % (step, loss, auc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

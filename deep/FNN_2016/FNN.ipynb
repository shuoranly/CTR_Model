{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict, namedtuple\n",
    "from tensorflow.python.keras.initializers import RandomNormal\n",
    "from tensorflow.python.keras.layers import  Embedding, Input, Flatten\n",
    "from tensorflow.python.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_data = pd.read_csv('../../data/criteo_sample.txt', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>260.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17668.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>87c6f83c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0429f84b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>c0d61a5c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30251.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>d4bb7bd8</td>\n",
       "      <td>6fc84bfb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5155d8a3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>be7c41b4</td>\n",
       "      <td>ded4aac9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>675c9258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2e01979f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>6d5d1302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16836.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>52e44668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e587c466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>3b183c5c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>25c88e42</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>0e8585d2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>0d4a6d1a</td>\n",
       "      <td>001f3601</td>\n",
       "      <td>92c878de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label   I1  I2     I3    I4       I5     I6   I7    I8     I9    ...     \\\n",
       "0      0  NaN   3  260.0   NaN  17668.0    NaN  NaN  33.0    NaN    ...      \n",
       "1      0  NaN  -1   19.0  35.0  30251.0  247.0  1.0  35.0  160.0    ...      \n",
       "2      0  0.0   0    2.0  12.0   2013.0  164.0  6.0  35.0  523.0    ...      \n",
       "3      0  NaN  13    1.0   4.0  16836.0  200.0  5.0   4.0   29.0    ...      \n",
       "4      0  0.0   0  104.0  27.0   1990.0  142.0  4.0  32.0   37.0    ...      \n",
       "\n",
       "        C17       C18       C19       C20       C21  C22       C23       C24  \\\n",
       "0  e5ba7672  87c6f83c       NaN       NaN  0429f84b  NaN  3a171ecb  c0d61a5c   \n",
       "1  d4bb7bd8  6fc84bfb       NaN       NaN  5155d8a3  NaN  be7c41b4  ded4aac9   \n",
       "2  e5ba7672  675c9258       NaN       NaN  2e01979f  NaN  bcdee96c  6d5d1302   \n",
       "3  e5ba7672  52e44668       NaN       NaN  e587c466  NaN  32c7478e  3b183c5c   \n",
       "4  e5ba7672  25c88e42  21ddcdc9  b1252a9d  0e8585d2  NaN  32c7478e  0d4a6d1a   \n",
       "\n",
       "        C25       C26  \n",
       "0       NaN       NaN  \n",
       "1       NaN       NaN  \n",
       "2       NaN       NaN  \n",
       "3       NaN       NaN  \n",
       "4  001f3601  92c878de  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "sam_data[sparse_features] = sam_data[sparse_features].fillna('-1', )\n",
    "sam_data[dense_features] = sam_data[dense_features].fillna(0, )\n",
    "target = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    sam_data[feat] = lbe.fit_transform(sam_data[feat])\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "sam_data[dense_features] = mms.fit_transform(sam_data[dense_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseFeat(namedtuple('SparseFeat', ['name', 'dimension', 'use_hash', 'dtype','embedding_name','embedding'])):\n",
    "    __slots__ = ()\n",
    "\n",
    "    def __new__(cls, name, dimension, use_hash=False, dtype=\"int32\", embedding_name=None,embedding=True):\n",
    "        if embedding and embedding_name is None:\n",
    "            embedding_name = name\n",
    "        return super(SparseFeat, cls).__new__(cls, name, dimension, use_hash, dtype, embedding_name,embedding)\n",
    "\n",
    "\n",
    "class DenseFeat(namedtuple('DenseFeat', ['name', 'dimension', 'dtype'])):\n",
    "    __slots__ = ()\n",
    "\n",
    "    def __new__(cls, name, dimension=1, dtype=\"float32\"):\n",
    "\n",
    "        return super(DenseFeat, cls).__new__(cls, name, dimension, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_features(feature_columns, include_varlen=True, mask_zero=True, prefix='',include_fixlen=True):\n",
    "    input_features = OrderedDict()\n",
    "    if include_fixlen:\n",
    "        for fc in feature_columns:\n",
    "            if isinstance(fc,SparseFeat):\n",
    "                input_features[fc.name] = Input(\n",
    "                    shape=(1,), name=prefix+fc.name, dtype=fc.dtype)\n",
    "            elif isinstance(fc,DenseFeat):\n",
    "                input_features[fc.name] = Input(\n",
    "                    shape=(fc.dimension,), name=prefix + fc.name, dtype=fc.dtype)\n",
    "    if include_varlen:\n",
    "        for fc in feature_columns:\n",
    "            if isinstance(fc,VarLenSparseFeat):\n",
    "                input_features[fc.name] = Input(shape=(fc.maxlen,), name=prefix + 'seq_' + fc.name,\n",
    "                                                      dtype=fc.dtype)\n",
    "        if not mask_zero:\n",
    "            for fc in feature_columns:\n",
    "                input_features[fc.name+\"_seq_length\"] = Input(shape=(\n",
    "                    1,), name=prefix + 'seq_length_' + fc.name)\n",
    "                input_features[fc.name+\"_seq_max_length\"] = fc.maxlen\n",
    "\n",
    "\n",
    "    return input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixlen_feature_names(feature_columns):\n",
    "    features = build_input_features(feature_columns, include_varlen=False,include_fixlen=True)\n",
    "    return list(features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_dict(sparse_feature_columns, varlen_sparse_feature_columns, embedding_size, init_std, seed, l2_reg,\n",
    "                          prefix='sparse_', seq_mask_zero=True):\n",
    "    if embedding_size == 'auto':\n",
    "        print(\"Notice:Do not use auto embedding in models other than DCN\")\n",
    "        sparse_embedding = {feat.embedding_name: Embedding(feat.dimension, 6 * int(pow(feat.dimension, 0.25)),\n",
    "                                                 embeddings_initializer=RandomNormal(\n",
    "                                                     mean=0.0, stddev=init_std, seed=seed),\n",
    "                                                 embeddings_regularizer=l2(l2_reg),\n",
    "                                                 name=prefix + '_emb_' + feat.name) for feat in\n",
    "                            sparse_feature_columns}\n",
    "    else:\n",
    "\n",
    "        sparse_embedding = {feat.embedding_name: Embedding(feat.dimension, embedding_size,\n",
    "                                                 embeddings_initializer=RandomNormal(\n",
    "                                                     mean=0.0, stddev=init_std, seed=seed),\n",
    "                                                 embeddings_regularizer=l2(\n",
    "                                                     l2_reg),\n",
    "                                                 name=prefix + '_emb_'  + feat.name) for feat in\n",
    "                            sparse_feature_columns}\n",
    "\n",
    "    if varlen_sparse_feature_columns and len(varlen_sparse_feature_columns) > 0:\n",
    "        for feat in varlen_sparse_feature_columns:\n",
    "            # if feat.name not in sparse_embedding:\n",
    "            if embedding_size == \"auto\":\n",
    "                sparse_embedding[feat.embedding_name] = Embedding(feat.dimension, 6 * int(pow(feat.dimension, 0.25)),\n",
    "                                                        embeddings_initializer=RandomNormal(\n",
    "                                                            mean=0.0, stddev=init_std, seed=seed),\n",
    "                                                        embeddings_regularizer=l2(\n",
    "                                                            l2_reg),\n",
    "                                                        name=prefix + '_seq_emb_' + feat.name,\n",
    "                                                        mask_zero=seq_mask_zero)\n",
    "\n",
    "            else:\n",
    "                sparse_embedding[feat.embedding_name] = Embedding(feat.dimension, embedding_size,\n",
    "                                                        embeddings_initializer=RandomNormal(\n",
    "                                                            mean=0.0, stddev=init_std, seed=seed),\n",
    "                                                        embeddings_regularizer=l2(\n",
    "                                                            l2_reg),\n",
    "                                                        name=prefix + '_seq_emb_' + feat.name,\n",
    "                                                        mask_zero=seq_mask_zero)\n",
    "\n",
    "\n",
    "    return sparse_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(feature_columns,l2_reg,init_std,seed,embedding_size, prefix=\"\",seq_mask_zero=True):\n",
    "    sparse_feature_columns = list(\n",
    "        filter(lambda x: isinstance(x, SparseFeat) and x.embedding, feature_columns)) if feature_columns else []\n",
    "    varlen_sparse_feature_columns = list(\n",
    "        filter(lambda x: isinstance(x, VarLenSparseFeat) and x.embedding, feature_columns)) if feature_columns else []\n",
    "    sparse_emb_dict = create_embedding_dict(sparse_feature_columns, varlen_sparse_feature_columns, embedding_size, init_std, seed,\n",
    "                                                 l2_reg, prefix=prefix + 'sparse',seq_mask_zero=seq_mask_zero)\n",
    "    return sparse_emb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_lookup(sparse_embedding_dict,sparse_input_dict,sparse_feature_columns,return_feat_list=(), mask_feat_list=()):\n",
    "    embedding_vec_list = []\n",
    "    for fc in sparse_feature_columns:\n",
    "        feature_name = fc.name\n",
    "        embedding_name = fc.embedding_name\n",
    "        if len(return_feat_list) == 0  or feature_name in return_feat_list and fc.embedding:\n",
    "            if fc.use_hash:\n",
    "                lookup_idx = Hash(fc.dimension,mask_zero=(feature_name in mask_feat_list))(sparse_input_dict[feature_name])\n",
    "            else:\n",
    "                lookup_idx = sparse_input_dict[feature_name]\n",
    "\n",
    "            embedding_vec_list.append(sparse_embedding_dict[embedding_name](lookup_idx))\n",
    "\n",
    "    return embedding_vec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varlen_embedding_lookup(embedding_dict, sequence_input_dict, varlen_sparse_feature_columns):\n",
    "    varlen_embedding_vec_dict = {}\n",
    "    for fc in varlen_sparse_feature_columns:\n",
    "        feature_name = fc.name\n",
    "        embedding_name = fc.embedding_name\n",
    "        if fc.use_hash:\n",
    "            lookup_idx = Hash(fc.dimension, mask_zero=True)(sequence_input_dict[feature_name])\n",
    "        else:\n",
    "            lookup_idx = sequence_input_dict[feature_name]\n",
    "        varlen_embedding_vec_dict[feature_name] = embedding_dict[embedding_name](lookup_idx)\n",
    "\n",
    "    return varlen_embedding_vec_dict\n",
    "\n",
    "def get_varlen_pooling_list(embedding_dict, features, varlen_sparse_feature_columns):\n",
    "    pooling_vec_list = []\n",
    "    for fc in varlen_sparse_feature_columns:\n",
    "        feature_name = fc.name\n",
    "        combiner = fc.combiner\n",
    "        feature_length_name = feature_name + '_seq_length'\n",
    "        if feature_length_name in features:\n",
    "            vec = SequencePoolingLayer(combiner, supports_masking=False)(\n",
    "            [embedding_dict[feature_name], features[feature_length_name]])\n",
    "        else:\n",
    "            vec = SequencePoolingLayer(combiner, supports_masking=True)(\n",
    "            embedding_dict[feature_name])\n",
    "        pooling_vec_list.append(vec)\n",
    "    return pooling_vec_list\n",
    "\n",
    "def get_dense_input(features,feature_columns):\n",
    "    dense_feature_columns = list(filter(lambda x:isinstance(x,DenseFeat),feature_columns)) if feature_columns else []\n",
    "    dense_input_list = []\n",
    "    for fc in dense_feature_columns:\n",
    "        dense_input_list.append(features[fc.name])\n",
    "    return dense_input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_from_feature_columns(features,feature_columns, embedding_size, l2_reg, init_std, seed,prefix='',seq_mask_zero=True,support_dense=True):\n",
    "    sparse_feature_columns = list(filter(lambda x:isinstance(x,SparseFeat),feature_columns)) if feature_columns else []\n",
    "    varlen_sparse_feature_columns = list(filter(lambda x: isinstance(x, VarLenSparseFeat), feature_columns)) if feature_columns else []\n",
    "\n",
    "    embedding_dict = create_embedding_matrix(feature_columns,l2_reg,init_std,seed,embedding_size, prefix=prefix,seq_mask_zero=seq_mask_zero)\n",
    "    sparse_embedding_list = embedding_lookup(\n",
    "        embedding_dict, features, sparse_feature_columns)\n",
    "    dense_value_list = get_dense_input(features,feature_columns)\n",
    "    if not support_dense and len(dense_value_list) >0:\n",
    "        raise ValueError(\"DenseFeat is not supported in dnn_feature_columns\")\n",
    "\n",
    "    sequence_embed_dict = varlen_embedding_lookup(embedding_dict,features,varlen_sparse_feature_columns)\n",
    "    sequence_embed_list = get_varlen_pooling_list(sequence_embed_dict, features, varlen_sparse_feature_columns)\n",
    "    sparse_embedding_list += sequence_embed_list\n",
    "\n",
    "    return sparse_embedding_list, dense_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, sam_data[feat].nunique())\n",
    "                           for feat in sparse_features] + [DenseFeat(feat, 1,)\n",
    "                          for feat in dense_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseFeat(name='C1', dimension=27, use_hash=False, dtype='int32', embedding_name='C1', embedding=True),\n",
       " SparseFeat(name='C2', dimension=92, use_hash=False, dtype='int32', embedding_name='C2', embedding=True),\n",
       " SparseFeat(name='C3', dimension=172, use_hash=False, dtype='int32', embedding_name='C3', embedding=True),\n",
       " SparseFeat(name='C4', dimension=157, use_hash=False, dtype='int32', embedding_name='C4', embedding=True),\n",
       " SparseFeat(name='C5', dimension=12, use_hash=False, dtype='int32', embedding_name='C5', embedding=True),\n",
       " SparseFeat(name='C6', dimension=7, use_hash=False, dtype='int32', embedding_name='C6', embedding=True),\n",
       " SparseFeat(name='C7', dimension=183, use_hash=False, dtype='int32', embedding_name='C7', embedding=True),\n",
       " SparseFeat(name='C8', dimension=19, use_hash=False, dtype='int32', embedding_name='C8', embedding=True),\n",
       " SparseFeat(name='C9', dimension=2, use_hash=False, dtype='int32', embedding_name='C9', embedding=True),\n",
       " SparseFeat(name='C10', dimension=142, use_hash=False, dtype='int32', embedding_name='C10', embedding=True),\n",
       " SparseFeat(name='C11', dimension=173, use_hash=False, dtype='int32', embedding_name='C11', embedding=True),\n",
       " SparseFeat(name='C12', dimension=170, use_hash=False, dtype='int32', embedding_name='C12', embedding=True),\n",
       " SparseFeat(name='C13', dimension=166, use_hash=False, dtype='int32', embedding_name='C13', embedding=True),\n",
       " SparseFeat(name='C14', dimension=14, use_hash=False, dtype='int32', embedding_name='C14', embedding=True),\n",
       " SparseFeat(name='C15', dimension=170, use_hash=False, dtype='int32', embedding_name='C15', embedding=True),\n",
       " SparseFeat(name='C16', dimension=168, use_hash=False, dtype='int32', embedding_name='C16', embedding=True),\n",
       " SparseFeat(name='C17', dimension=9, use_hash=False, dtype='int32', embedding_name='C17', embedding=True),\n",
       " SparseFeat(name='C18', dimension=127, use_hash=False, dtype='int32', embedding_name='C18', embedding=True),\n",
       " SparseFeat(name='C19', dimension=44, use_hash=False, dtype='int32', embedding_name='C19', embedding=True),\n",
       " SparseFeat(name='C20', dimension=4, use_hash=False, dtype='int32', embedding_name='C20', embedding=True),\n",
       " SparseFeat(name='C21', dimension=169, use_hash=False, dtype='int32', embedding_name='C21', embedding=True),\n",
       " SparseFeat(name='C22', dimension=6, use_hash=False, dtype='int32', embedding_name='C22', embedding=True),\n",
       " SparseFeat(name='C23', dimension=10, use_hash=False, dtype='int32', embedding_name='C23', embedding=True),\n",
       " SparseFeat(name='C24', dimension=125, use_hash=False, dtype='int32', embedding_name='C24', embedding=True),\n",
       " SparseFeat(name='C25', dimension=20, use_hash=False, dtype='int32', embedding_name='C25', embedding=True),\n",
       " SparseFeat(name='C26', dimension=90, use_hash=False, dtype='int32', embedding_name='C26', embedding=True),\n",
       " DenseFeat(name='I1', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I2', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I3', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I4', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I5', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I6', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I7', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I8', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I9', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I10', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I11', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I12', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I13', dimension=1, dtype='float32')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixlen_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "fixlen_feature_names = get_fixlen_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(sam_data, test_size=0.2)\n",
    "train_model_input = [train[name] for name in fixlen_feature_names]\n",
    "test_model_input = [test[name] for name in fixlen_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary')\n",
    "model.compile(\"adam\", \"binary_crossentropy\",\n",
    "                  metrics=['binary_crossentropy'], )\n",
    "\n",
    "history = model.fit(train_model_input, train[target].values,\n",
    "                        batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
    "pred_ans = model.predict(test_model_input, batch_size=256)\n",
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
